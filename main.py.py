# -*- coding: utf-8 -*-
"""Assignment2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11aaeQ1YLtW71rGSvrm_qalEFZ22j9BUa
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d noulam/tomato

!ls

!unzip tomato.zip

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

TRAIN_DIR = "/content/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/train"
VALID_DIR = "/content/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/valid"

def count_images(folder_path):
    total_images = 0
    for class_name in os.listdir(folder_path):
        class_path = os.path.join(folder_path, class_name)
        if os.path.isdir(class_path):
            total_images += len(os.listdir(class_path))
    return total_images

train_count = count_images(TRAIN_DIR)
valid_count = count_images(VALID_DIR)
total_count = train_count + valid_count

print("Training images:", train_count)
print("Validation images:", valid_count)
print("Total images (instances):", total_count)

train_classes = os.listdir(TRAIN_DIR)
valid_classes = os.listdir(VALID_DIR)

print("Number of classes in train:", len(train_classes))
print("Number of classes in valid:", len(valid_classes))

def count_images(folder):
    class_counts = {cls: len(os.listdir(os.path.join(folder, cls))) for cls in os.listdir(folder)}
    return class_counts

train_counts = count_images(TRAIN_DIR)
valid_counts = count_images(VALID_DIR)

print("Train counts:", train_counts)
print("Valid counts:", valid_counts)

import matplotlib.pyplot as plt

plt.figure(figsize=(12,5))
plt.bar(train_counts.keys(), train_counts.values())
plt.xticks(rotation=90)
plt.title("Train Dataset Class Distribution")
plt.show()

plt.figure(figsize=(12,5))
plt.bar(valid_counts.keys(), valid_counts.values())
plt.xticks(rotation=90)
plt.title("Validation Dataset Class Distribution")
plt.show()

from PIL import Image

corrupt_images = []

for cls in train_classes:
    cls_path = os.path.join(TRAIN_DIR, cls)
    for img_name in os.listdir(cls_path):
        img_path = os.path.join(cls_path, img_name)
        try:
            img = Image.open(img_path)
            img.verify()
        except:
            corrupt_images.append(img_path)

print("Number of corrupt images:", len(corrupt_images))

from PIL import Image
import random

def show_samples(folder, n=6):
    classes = os.listdir(folder)
    plt.figure(figsize=(12,8))
    for i, cls in enumerate(random.sample(classes, n)):
        img_name = random.choice(os.listdir(os.path.join(folder, cls)))
        img_path = os.path.join(folder, cls, img_name)
        img = Image.open(img_path)

        plt.subplot(2,3,i+1)
        plt.imshow(img)
        plt.title(cls)
        plt.axis('off')
    plt.tight_layout()
    plt.show()

# Samples from train
show_samples(TRAIN_DIR)

# Samples from validation
show_samples(VALID_DIR)

# Normalization and augmentation for training set
train_datagen = ImageDataGenerator(
    rescale=.1/255,       # normalize pixel values
    rotation_range=30,    # random rotation
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
     shear_range=0.2
)

# Only normalization for validation
valid_datagen = ImageDataGenerator(rescale=1./255)

# Create generators
train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

valid_generator = valid_datagen.flow_from_directory(
    VALID_DIR,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)
valid_generator.reset()

num_classes = len(train_generator.class_indices)

cnn_model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    # Conv2D(128, (3,3), activation='relu'),
    # MaxPooling2D(2,2),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(train_generator.num_classes, activation='softmax')
])

cnn_model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

cnn_model.summary()

history = cnn_model.fit(
    train_generator,
    epochs=25,
    validation_data=valid_generator
)

import cv2
from sklearn.model_selection import train_test_split
X = []
y = []

for class_name, class_index in train_generator.class_indices.items():
    class_dir = os.path.join(TRAIN_DIR, class_name)

    for img_name in os.listdir(class_dir):
        img_path = os.path.join(class_dir, img_name)

        img = cv2.imread(img_path)
        img = cv2.resize(img, (64, 64))   # smaller for RF
        img = img / 255.0                 # normalize

        X.append(img.flatten())
        y.append(class_index)

X = np.array(X)
y = np.array(y)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)

rf.fit(X_train, y_train)

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score

import cv2

# Load all images into numpy arrays (small subset for demo)
X, y = [], []

for cls, idx in train_generator.class_indices.items():
    cls_folder = os.path.join(TRAIN_DIR, cls)
    for img_name in os.listdir(cls_folder):
        img_path = os.path.join(cls_folder, img_name)
        img = cv2.imread(img_path)        # read image
        img = cv2.resize(img, (64,64))   # resize smaller for speed
        X.append(img.flatten())           # flatten image
        y.append(idx)

X = np.array(X)
y = np.array(y)

# Split a validation set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

print("KNN Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Reset generator
valid_generator.reset()

# Predict all validation samples
y_pred_prob = cnn_model.predict(valid_generator, steps=len(valid_generator), verbose=1)

# Convert probabilities to class indices
y_pred_classes = np.argmax(y_pred_prob, axis=1)

# True labels from generator
y_true = valid_generator.classes

# Class names
class_labels = list(valid_generator.class_indices.keys())

# Classification report
from sklearn.metrics import classification_report, accuracy_score

print("CNN Accuracy:", accuracy_score(y_true, y_pred_classes))
print(classification_report(y_true, y_pred_classes, target_names=class_labels))

print("Training Accuracy:", history.history['accuracy'][-1])
print("Validation Accuracy:", history.history['val_accuracy'][-1])

import matplotlib.pyplot as plt
import seaborn as sns

cm = confusion_matrix(y_true, y_pred_classes)

plt.figure(figsize=(12,10))
sns.heatmap(cm, annot=False, cmap="Blues")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix - CNN Model")
plt.show()

plt.figure(figsize=(12,5))

# Accuracy
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title("Accuracy Curve")

# Loss
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title("Loss Curve")

plt.show()

import os
import random

# Choose a random class folder
random_class = random.choice(os.listdir(VALID_DIR))

# Choose a random image from that class
random_image = random.choice(os.listdir(os.path.join(VALID_DIR, random_class)))

# Full image path
img_path = os.path.join(VALID_DIR, random_class, random_image)

print("Actual class:", random_class)
print("Image path:", img_path)

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

img = image.load_img(img_path, target_size=(128, 128))
img_array = image.img_to_array(img) / 255.0
img_array = np.expand_dims(img_array, axis=0)

prediction = cnn_model.predict(img_array)
predicted_class = class_labels[np.argmax(prediction)]

plt.imshow(img)
plt.axis('off')
plt.title(f"Predicted: {predicted_class}")
plt.show()